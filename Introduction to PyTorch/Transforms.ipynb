{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "In PyTorch, we use `Transforms` to process data and make it suitable for training. All `TorchVision` datasets have two parameters:\n",
    "- `transform` defines the feature-scope manipulations\n",
    "- `target_transform` defines the label-scope manipulations\n",
    "\n",
    "Take the FashionMNIST data for instance, the features are in PIL `Image` format, and the labels are integers corresponding to the classes. To make the data suitable for training, we need the features to be normalized tensors and the labels as one-hot encoders, which can be tackled with PyTorch's `ToTensor` and `Lambda` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can define transforms of the dataset for easier processing by the neural nets. For the feature transform, the corresponding parameter is `transform`, here we define it using `ToTensor` to convert a PIL image or NumPy `ndarray` into a `FloatTensor`, and scales the image's pixel intensity values from $[0, 255]$ to $[0., 1.]$. For the label transform, the corresponding parameter is `target_transform`, here we define the function using `Lambda Transforms` for the `target_transform`, which first creates a zero tensor of size $10$ and calls the `scatter-` function to assign `value=1` on indices provided by vector `y`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(), # converts a PIL image or NumPy `ndarray` into a `FloatTensor`, and scales the image pixel intensity values into [0., 1.]\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)) # lambda function for one-hot encoding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
